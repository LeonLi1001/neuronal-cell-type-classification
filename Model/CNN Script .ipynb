{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 05:30:40.071426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/np/3n8gblwj5054scn97qw91dpc0000gn/T/ipykernel_10051/1943269388.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Model\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "hidden_layers = 3 # default value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1d_cnn(input_size, hls = 3):\n",
    "    model = tf.keras.Sequential()\n",
    "    for i in range(hls):\n",
    "        if i == 0:\n",
    "            model.add(Conv1D(filters=32, kernel_size=17, activation='relu', input_shape=input_size))\n",
    "        else: \n",
    "            model.add(Conv1D(filters=64, kernel_size=17, activation='relu'))\n",
    "                      \n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(75, activation='softmax'))\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer=\"adam\", loss=loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metric function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictionTable(predictions):\n",
    "    y_pred = []\n",
    "    for pred in predictions:\n",
    "        y_pred.append(np.argmax(pred))\n",
    "    cm = pd.DataFrame(metrics.confusion_matrix(y_val, y_pred))\n",
    "    new_cm = pd.DataFrame(columns = [\"TN\", \"FP\", \"FN\", \"TP\"])\n",
    "    for i in range(75):\n",
    "        true_negative = 0\n",
    "        for j in range(75):\n",
    "            if j == i:\n",
    "                continue\n",
    "            true_negative += sum(cm[j][0:i].append(cm[j][i+1:]))\n",
    "        new_cm.loc[i] = [true_negative, sum(cm[i][0:i].append(cm[i][i+1:])), sum(cm.iloc[i][0:i].append(cm.iloc[i][i+1:])), cm[i][i]]\n",
    "    cm = new_cm\n",
    "    cm[\"TN\"] = cm[\"TN\"].astype(np.int64)\n",
    "    cm[\"FP\"] = cm[\"FP\"].astype(np.int64)\n",
    "    cm[\"FN\"] = cm[\"FN\"].astype(np.int64)\n",
    "    cm[\"TP\"] = cm[\"TP\"].astype(np.int64)\n",
    "    cm = cm.assign(precision = cm[\"TP\"] / (cm[\"TP\"] + cm[\"FP\"]))\n",
    "    cm[\"precision\"].astype(np.float64)\n",
    "    cm = cm.assign(recall = cm[\"TP\"] / (cm[\"TP\"] + cm[\"FN\"]))\n",
    "    cm[\"recall\"].astype(np.float64)\n",
    "    cm = cm.assign(f1 = 2 * 1 / ((1 / cm[\"precision\"]) + (1 / cm[\"recall\"])))\n",
    "    cm = cm.assign(fbeta = (1 + 0.5 ** 2) * (cm[\"precision\"] * cm[\"recall\"]) / ((0.5 ** 2 * cm[\"precision\"]) + cm[\"recall\"]))\n",
    "    cm[\"fbeta\"].fillna(0, inplace=True)\n",
    "    cm[\"cluster\"] = labels[\"Cluster\"]\n",
    "    cm = cm.merge(dataset_sizes, how = 'inner', left_on='cluster', right_on=0)\n",
    "    cm.drop(columns=0, inplace = True)\n",
    "    cm.rename(columns={1:\"size\"}, inplace = True)\n",
    "    cm[\"log_size\"] = np.log2(cm[\"size\"])\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the input data \n",
    "\n",
    "\n",
    "model = create_1d_cnn(hidden_layers = hidden_layers, input_size = input_size)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0)\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=1024, callbacks=callback, verbose=1)\n",
    "\n",
    "\n",
    "predictions = tf.nn.softmax(model.predict(x_val)).numpy()\n",
    "cm = PredictionTable(predictions)\n",
    "\n",
    "fbeta_dict[activation_function] = []\n",
    "fbeta_dict[activation_function].extend(list(cm[\"fbeta\"]))\n",
    "\n",
    "Title = str(hidden_layers)\n",
    "\n",
    "print(Title)\n",
    "fig = cm.plot.scatter(x=\"log_size\", y=\"fbeta\",ylim=[-0.05, 1.05], title=Title).get_figure()\n",
    "# path = \"Plots/\" + Title + \".png\"\n",
    "# plt.savefig(path)\n",
    "# Loss\n",
    "ax = plt.figure().gca()\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.plot(history.history['loss'], label=\"Train Loss\")\n",
    "plt.plot(history.history['val_loss'], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(Title + \" Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylim(0, 1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python neuroclass",
   "language": "python",
   "name": "neuroclass_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
